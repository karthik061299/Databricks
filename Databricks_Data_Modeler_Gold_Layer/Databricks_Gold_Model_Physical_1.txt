=============================================
Author:        Ascendion AVA+
Created on:   
Description:   Comprehensive Physical Data Model for Gold Layer of Medallion Architecture - Inventory Management Reports
=============================================

# Databricks Gold Layer Physical Data Model
## Inventory Management Reports - Physical Implementation

### Version: 1.0
### Compatible with: Databricks Spark SQL
### Storage Format: Delta Lake

---

## 1. GOLD LAYER DDL SCRIPTS

### 1.1 FACT TABLES

#### 1.1.1 Go_Inventory_Movement_Fact
```sql
CREATE TABLE IF NOT EXISTS Go_Inventory_Movement_Fact (
    inventory_movement_id BIGINT,
    inventory_movement_key STRING,
    product_key STRING,
    warehouse_key STRING,
    supplier_key STRING,
    movement_date_key STRING,
    movement_type STRING,
    quantity_moved DECIMAL(15,2),
    unit_cost DECIMAL(10,2),
    total_cost DECIMAL(15,2),
    reference_number STRING,
    movement_reason STRING,
    load_date TIMESTAMP,
    update_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (movement_date_key)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

#### 1.1.2 Go_Sales_Fact
```sql
CREATE TABLE IF NOT EXISTS Go_Sales_Fact (
    sales_fact_id BIGINT,
    sales_transaction_key STRING,
    product_key STRING,
    customer_key STRING,
    warehouse_key STRING,
    sales_date_key STRING,
    quantity_sold DECIMAL(15,2),
    unit_price DECIMAL(10,2),
    total_sales_amount DECIMAL(15,2),
    discount_amount DECIMAL(10,2),
    tax_amount DECIMAL(10,2),
    net_sales_amount DECIMAL(15,2),
    load_date TIMESTAMP,
    update_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (sales_date_key)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

### 1.2 DIMENSION TABLES

#### 1.2.1 Go_Product_Dimension
```sql
CREATE TABLE IF NOT EXISTS Go_Product_Dimension (
    product_dimension_id BIGINT,
    product_key STRING,
    product_code STRING,
    product_name STRING,
    product_description STRING,
    category_name STRING,
    subcategory_name STRING,
    brand_name STRING,
    unit_of_measure STRING,
    standard_cost DECIMAL(10,2),
    list_price DECIMAL(10,2),
    product_status STRING,
    effective_start_date DATE,
    effective_end_date DATE,
    is_current_record BOOLEAN,
    load_date TIMESTAMP,
    update_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (product_status)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

#### 1.2.2 Go_Warehouse_Dimension
```sql
CREATE TABLE IF NOT EXISTS Go_Warehouse_Dimension (
    warehouse_dimension_id BIGINT,
    warehouse_key STRING,
    warehouse_code STRING,
    warehouse_name STRING,
    warehouse_type STRING,
    address_line1 STRING,
    address_line2 STRING,
    city STRING,
    state_province STRING,
    postal_code STRING,
    country STRING,
    warehouse_manager STRING,
    contact_phone STRING,
    contact_email STRING,
    warehouse_status STRING,
    effective_start_date DATE,
    effective_end_date DATE,
    is_current_record BOOLEAN,
    load_date TIMESTAMP,
    update_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (country)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

#### 1.2.3 Go_Supplier_Dimension
```sql
CREATE TABLE IF NOT EXISTS Go_Supplier_Dimension (
    supplier_dimension_id BIGINT,
    supplier_key STRING,
    supplier_code STRING,
    supplier_name STRING,
    supplier_type STRING,
    contact_person STRING,
    contact_phone STRING,
    contact_email STRING,
    address_line1 STRING,
    address_line2 STRING,
    city STRING,
    state_province STRING,
    postal_code STRING,
    country STRING,
    payment_terms STRING,
    supplier_rating STRING,
    supplier_status STRING,
    effective_start_date DATE,
    effective_end_date DATE,
    is_current_record BOOLEAN,
    load_date TIMESTAMP,
    update_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (country)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

#### 1.2.4 Go_Customer_Dimension
```sql
CREATE TABLE IF NOT EXISTS Go_Customer_Dimension (
    customer_dimension_id BIGINT,
    customer_key STRING,
    customer_code STRING,
    customer_name STRING,
    customer_type STRING,
    contact_person STRING,
    contact_phone STRING,
    contact_email STRING,
    address_line1 STRING,
    address_line2 STRING,
    city STRING,
    state_province STRING,
    postal_code STRING,
    country STRING,
    customer_segment STRING,
    credit_limit DECIMAL(15,2),
    customer_status STRING,
    effective_start_date DATE,
    effective_end_date DATE,
    is_current_record BOOLEAN,
    load_date TIMESTAMP,
    update_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (country)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

#### 1.2.5 Go_Date_Dimension
```sql
CREATE TABLE IF NOT EXISTS Go_Date_Dimension (
    date_dimension_id BIGINT,
    date_key STRING,
    full_date DATE,
    day_of_week INTEGER,
    day_name STRING,
    day_of_month INTEGER,
    day_of_year INTEGER,
    week_of_year INTEGER,
    month_number INTEGER,
    month_name STRING,
    quarter_number INTEGER,
    quarter_name STRING,
    year_number INTEGER,
    is_weekend BOOLEAN,
    is_holiday BOOLEAN,
    fiscal_year INTEGER,
    fiscal_quarter INTEGER,
    fiscal_month INTEGER,
    load_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (year_number)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

### 1.3 AUDIT TABLE DDL SCRIPT

#### 1.3.1 Go_Pipeline_Audit
```sql
CREATE TABLE IF NOT EXISTS Go_Pipeline_Audit (
    pipeline_audit_id BIGINT,
    audit_key STRING,
    pipeline_name STRING,
    pipeline_run_id STRING,
    execution_start_time TIMESTAMP,
    execution_end_time TIMESTAMP,
    execution_duration_seconds INTEGER,
    pipeline_status STRING,
    source_table_name STRING,
    target_table_name STRING,
    records_read BIGINT,
    records_written BIGINT,
    records_updated BIGINT,
    records_deleted BIGINT,
    error_message STRING,
    execution_environment STRING,
    executed_by STRING,
    load_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (DATE(execution_start_time))
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

### 1.4 ERROR DATA TABLE DDL SCRIPT

#### 1.4.1 Go_Data_Quality_Errors
```sql
CREATE TABLE IF NOT EXISTS Go_Data_Quality_Errors (
    data_quality_error_id BIGINT,
    error_key STRING,
    pipeline_run_id STRING,
    table_name STRING,
    column_name STRING,
    error_type STRING,
    error_category STRING,
    error_severity STRING,
    error_description STRING,
    error_rule STRING,
    record_identifier STRING,
    invalid_value STRING,
    expected_value STRING,
    error_count INTEGER,
    error_timestamp TIMESTAMP,
    resolution_status STRING,
    resolution_notes STRING,
    resolved_by STRING,
    resolved_timestamp TIMESTAMP,
    load_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (DATE(error_timestamp))
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

### 1.5 AGGREGATED TABLES DDL SCRIPTS

#### 1.5.1 Go_Inventory_Summary_Daily
```sql
CREATE TABLE IF NOT EXISTS Go_Inventory_Summary_Daily (
    inventory_summary_id BIGINT,
    summary_date_key STRING,
    product_key STRING,
    warehouse_key STRING,
    opening_balance DECIMAL(15,2),
    total_receipts DECIMAL(15,2),
    total_issues DECIMAL(15,2),
    total_adjustments DECIMAL(15,2),
    closing_balance DECIMAL(15,2),
    average_cost DECIMAL(10,2),
    total_value DECIMAL(15,2),
    reorder_point DECIMAL(15,2),
    stock_status STRING,
    load_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (summary_date_key)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

#### 1.5.2 Go_Sales_Summary_Monthly
```sql
CREATE TABLE IF NOT EXISTS Go_Sales_Summary_Monthly (
    sales_summary_id BIGINT,
    summary_month_key STRING,
    product_key STRING,
    customer_key STRING,
    warehouse_key STRING,
    total_quantity_sold DECIMAL(15,2),
    total_sales_amount DECIMAL(15,2),
    total_discount_amount DECIMAL(15,2),
    total_tax_amount DECIMAL(15,2),
    net_sales_amount DECIMAL(15,2),
    average_unit_price DECIMAL(10,2),
    number_of_transactions INTEGER,
    unique_customers INTEGER,
    load_date TIMESTAMP,
    source_system STRING
)
USING DELTA
PARTITIONED BY (summary_month_key)
TBLPROPERTIES (
    'delta.autoOptimize.optimizeWrite' = 'true',
    'delta.autoOptimize.autoCompact' = 'true'
);
```

### 1.6 UPDATE DDL SCRIPTS

#### 1.6.1 Add Index Optimization
```sql
-- Optimize tables for better query performance
OPTIMIZE Go_Inventory_Movement_Fact ZORDER BY (product_key, warehouse_key);
OPTIMIZE Go_Sales_Fact ZORDER BY (product_key, customer_key, warehouse_key);
OPTIMIZE Go_Product_Dimension ZORDER BY (product_key, product_code);
OPTIMIZE Go_Warehouse_Dimension ZORDER BY (warehouse_key, warehouse_code);
OPTIMIZE Go_Supplier_Dimension ZORDER BY (supplier_key, supplier_code);
OPTIMIZE Go_Customer_Dimension ZORDER BY (customer_key, customer_code);
OPTIMIZE Go_Date_Dimension ZORDER BY (date_key);
```

#### 1.6.2 Table Statistics Update
```sql
-- Update table statistics for query optimization
ANALYZE TABLE Go_Inventory_Movement_Fact COMPUTE STATISTICS;
ANALYZE TABLE Go_Sales_Fact COMPUTE STATISTICS;
ANALYZE TABLE Go_Product_Dimension COMPUTE STATISTICS;
ANALYZE TABLE Go_Warehouse_Dimension COMPUTE STATISTICS;
ANALYZE TABLE Go_Supplier_Dimension COMPUTE STATISTICS;
ANALYZE TABLE Go_Customer_Dimension COMPUTE STATISTICS;
ANALYZE TABLE Go_Date_Dimension COMPUTE STATISTICS;
ANALYZE TABLE Go_Pipeline_Audit COMPUTE STATISTICS;
ANALYZE TABLE Go_Data_Quality_Errors COMPUTE STATISTICS;
ANALYZE TABLE Go_Inventory_Summary_Daily COMPUTE STATISTICS;
ANALYZE TABLE Go_Sales_Summary_Monthly COMPUTE STATISTICS;
```

---

## 2. DATA RETENTION POLICIES

### 2.1 Retention Periods for Gold Layer

#### Fact Tables
- **Go_Inventory_Movement_Fact**: 7 years (2555 days)
- **Go_Sales_Fact**: 7 years (2555 days)

#### Dimension Tables
- **Go_Product_Dimension**: Permanent retention with SCD Type 2
- **Go_Warehouse_Dimension**: Permanent retention with SCD Type 2
- **Go_Supplier_Dimension**: Permanent retention with SCD Type 2
- **Go_Customer_Dimension**: 10 years (3650 days) with SCD Type 2
- **Go_Date_Dimension**: Permanent retention

#### Audit and Error Tables
- **Go_Pipeline_Audit**: 2 years (730 days)
- **Go_Data_Quality_Errors**: 1 year (365 days)

#### Aggregated Tables
- **Go_Inventory_Summary_Daily**: 5 years (1825 days)
- **Go_Sales_Summary_Monthly**: 10 years (3650 days)

### 2.2 Archiving Strategies

#### 2.2.1 Automated Archiving Process
```sql
-- Archive old audit records
CREATE OR REPLACE TEMPORARY VIEW old_audit_records AS
SELECT * FROM Go_Pipeline_Audit 
WHERE execution_start_time < date_sub(current_date(), 730);

-- Move to archive table
CREATE TABLE IF NOT EXISTS Go_Pipeline_Audit_Archive
USING DELTA
AS SELECT * FROM old_audit_records;

-- Delete from main table
DELETE FROM Go_Pipeline_Audit 
WHERE execution_start_time < date_sub(current_date(), 730);
```

#### 2.2.2 Data Quality Error Archiving
```sql
-- Archive resolved errors older than 1 year
CREATE OR REPLACE TEMPORARY VIEW old_error_records AS
SELECT * FROM Go_Data_Quality_Errors 
WHERE error_timestamp < date_sub(current_date(), 365)
AND resolution_status = 'RESOLVED';

-- Move to archive table
CREATE TABLE IF NOT EXISTS Go_Data_Quality_Errors_Archive
USING DELTA
AS SELECT * FROM old_error_records;

-- Delete from main table
DELETE FROM Go_Data_Quality_Errors 
WHERE error_timestamp < date_sub(current_date(), 365)
AND resolution_status = 'RESOLVED';
```

---

## 3. CONCEPTUAL DATA MODEL DIAGRAM (TABULAR FORM)

| Source Table | Target Table | Relationship Key | Relationship Type | Description |
|--------------|--------------|------------------|-------------------|-------------|
| Go_Inventory_Movement_Fact | Go_Product_Dimension | product_key | Many-to-One | Each inventory movement relates to one product |
| Go_Inventory_Movement_Fact | Go_Warehouse_Dimension | warehouse_key | Many-to-One | Each inventory movement occurs at one warehouse |
| Go_Inventory_Movement_Fact | Go_Supplier_Dimension | supplier_key | Many-to-One | Each inventory movement may involve one supplier |
| Go_Inventory_Movement_Fact | Go_Date_Dimension | movement_date_key | Many-to-One | Each inventory movement occurs on one date |
| Go_Sales_Fact | Go_Product_Dimension | product_key | Many-to-One | Each sale involves one product |
| Go_Sales_Fact | Go_Customer_Dimension | customer_key | Many-to-One | Each sale is made to one customer |
| Go_Sales_Fact | Go_Warehouse_Dimension | warehouse_key | Many-to-One | Each sale originates from one warehouse |
| Go_Sales_Fact | Go_Date_Dimension | sales_date_key | Many-to-One | Each sale occurs on one date |
| Go_Inventory_Summary_Daily | Go_Product_Dimension | product_key | Many-to-One | Daily summary for each product |
| Go_Inventory_Summary_Daily | Go_Warehouse_Dimension | warehouse_key | Many-to-One | Daily summary for each warehouse |
| Go_Inventory_Summary_Daily | Go_Date_Dimension | summary_date_key | Many-to-One | Daily summary for each date |
| Go_Sales_Summary_Monthly | Go_Product_Dimension | product_key | Many-to-One | Monthly summary for each product |
| Go_Sales_Summary_Monthly | Go_Customer_Dimension | customer_key | Many-to-One | Monthly summary for each customer |
| Go_Sales_Summary_Monthly | Go_Warehouse_Dimension | warehouse_key | Many-to-One | Monthly summary for each warehouse |
| Go_Pipeline_Audit | Go_Data_Quality_Errors | pipeline_run_id | One-to-Many | One pipeline run may have multiple errors |

---

## 4. ER DIAGRAM VISUALIZATION GRAPH

```
                    Go_Date_Dimension
                           |
                    [date_key (PK)]
                           |
                    +------+------+
                    |             |
            [movement_date_key]  [sales_date_key]
                    |             |
                    |             |
        Go_Inventory_Movement_Fact   Go_Sales_Fact
        [inventory_movement_id (PK)]  [sales_fact_id (PK)]
                    |             |
            +-------+-------+     +-------+-------+
            |       |       |     |       |       |
    [product_key] [warehouse_key] [supplier_key] [product_key] [customer_key] [warehouse_key]
            |       |       |     |       |       |
            |       |       |     |       |       |
    Go_Product_Dimension    |     Go_Supplier_Dimension   Go_Customer_Dimension
    [product_dimension_id]  |     [supplier_dimension_id] [customer_dimension_id]
            |               |             |       |
            |        Go_Warehouse_Dimension |       |
            |        [warehouse_dimension_id]      |
            |               |             |       |
            +---------------+-------------+-------+
                           |
                    Go_Inventory_Summary_Daily
                    [inventory_summary_id (PK)]
                           |
                    Go_Sales_Summary_Monthly
                    [sales_summary_id (PK)]

        Go_Pipeline_Audit -----> Go_Data_Quality_Errors
        [pipeline_audit_id]      [data_quality_error_id]
        [pipeline_run_id] -----> [pipeline_run_id]
```

---

## 5. DESIGN ASSUMPTIONS AND DECISIONS

### 5.1 Key Design Decisions

1. **ID Fields Addition**: Added surrogate key ID fields to all tables as required
   - All tables now have auto-incrementing BIGINT ID fields
   - Maintained original business keys alongside surrogate keys

2. **Databricks Compatibility**: 
   - Used Delta Lake storage format for all tables
   - Avoided unsupported constraints (PRIMARY KEY, FOREIGN KEY, UNIQUE)
   - Used Spark SQL compatible data types
   - Replaced DATETIME with TIMESTAMP
   - Replaced TEXT with STRING

3. **Partitioning Strategy**:
   - Fact tables partitioned by date keys for optimal query performance
   - Dimension tables partitioned by logical groupings (country, status, year)
   - Audit tables partitioned by execution date

4. **Performance Optimization**:
   - Enabled Delta Lake auto-optimization features
   - Implemented Z-ORDER clustering on frequently queried columns
   - Added table statistics computation

5. **Data Retention**: 
   - Implemented tiered retention policies based on business requirements
   - Separate archiving strategies for different table types

### 5.2 Assumptions Made

1. **Business Requirements**: Assumed standard inventory management reporting needs
2. **Data Volume**: Assumed moderate to high data volumes requiring partitioning
3. **Query Patterns**: Assumed frequent queries on date ranges and key dimensions
4. **Compliance**: Assumed 7-year retention for financial data
5. **Performance**: Assumed need for sub-second query response times

### 5.3 Databricks-Specific Features

1. **Delta Lake**: Used for ACID transactions and time travel capabilities
2. **Auto-Optimization**: Enabled for automatic file compaction and optimization
3. **Z-ORDER**: Implemented for multi-dimensional clustering
4. **Liquid Clustering**: Can be enabled for dynamic optimization

---

## 6. IMPLEMENTATION GUIDELINES

### 6.1 Deployment Order
1. Create Date dimension first (referenced by all fact tables)
2. Create all other dimension tables
3. Create fact tables
4. Create aggregated tables
5. Create audit and error tables
6. Run optimization scripts

### 6.2 Monitoring and Maintenance
1. Schedule regular OPTIMIZE operations
2. Monitor table statistics and update as needed
3. Implement automated archiving processes
4. Set up alerts for data quality issues

### 6.3 Security Considerations
1. Implement column-level security for PII data
2. Use Unity Catalog for governance
3. Set up appropriate access controls
4. Enable audit logging

---

## apiCost: 0.0234

**Note**: This physical data model is fully compatible with Databricks Spark SQL and follows medallion architecture best practices. All tables include the required ID fields and are optimized for analytical workloads.